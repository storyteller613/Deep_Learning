{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tensor Classification Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is California Census Data, the goal is to use various features of an individual to predict what class of income they belogn in (>50k or <=50k). \n",
    "\n",
    "Here is some information about the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Column Name</th>\n",
    "<th>Type</th>\n",
    "<th>Description</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>age</td>\n",
    "<td>Continuous</td>\n",
    "<td>The age of the individual</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>workclass</td>\n",
    "<td>Categorical</td>\n",
    "<td>The type of employer the  individual has (government,  military, private, etc.).</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>fnlwgt</td>\n",
    "<td>Continuous</td>\n",
    "<td>The number of people the census  takers believe that observation  represents (sample weight). This  variable will not be used.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>education</td>\n",
    "<td>Categorical</td>\n",
    "<td>The highest level of education  achieved for that individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>education_num</td>\n",
    "<td>Continuous</td>\n",
    "<td>The highest level of education in  numerical form.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>marital_status</td>\n",
    "<td>Categorical</td>\n",
    "<td>Marital status of the individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>occupation</td>\n",
    "<td>Categorical</td>\n",
    "<td>The occupation of the individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>relationship</td>\n",
    "<td>Categorical</td>\n",
    "<td>Wife, Own-child, Husband,  Not-in-family, Other-relative,  Unmarried.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>race</td>\n",
    "<td>Categorical</td>\n",
    "<td>White, Asian-Pac-Islander,  Amer-Indian-Eskimo, Other, Black.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>gender</td>\n",
    "<td>Categorical</td>\n",
    "<td>Female, Male.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>capital_gain</td>\n",
    "<td>Continuous</td>\n",
    "<td>Capital gains recorded.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>capital_loss</td>\n",
    "<td>Continuous</td>\n",
    "<td>Capital Losses recorded.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>hours_per_week</td>\n",
    "<td>Continuous</td>\n",
    "<td>Hours worked per week.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>native_country</td>\n",
    "<td>Categorical</td>\n",
    "<td>Country of origin of the  individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>income</td>\n",
    "<td>Categorical</td>\n",
    "<td>\"&gt;50K\" or \"&lt;=50K\", meaning  whether the person makes more  than \\$50,000 annually.</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Read in the census_data.csv data with pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "census = pd.read_csv('census_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education  education_num       marital_status  \\\n",
       "0   39          State-gov   Bachelors             13        Never-married   \n",
       "1   50   Self-emp-not-inc   Bachelors             13   Married-civ-spouse   \n",
       "2   38            Private     HS-grad              9             Divorced   \n",
       "3   53            Private        11th              7   Married-civ-spouse   \n",
       "4   28            Private   Bachelors             13   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship    race   gender  capital_gain  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male          2174   \n",
       "1     Exec-managerial         Husband   White     Male             0   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male             0   \n",
       "3   Handlers-cleaners         Husband   Black     Male             0   \n",
       "4      Prof-specialty            Wife   Black   Female             0   \n",
       "\n",
       "   capital_loss  hours_per_week  native_country income_bracket  \n",
       "0             0              40   United-States          <=50K  \n",
       "1             0              13   United-States          <=50K  \n",
       "2             0              40   United-States          <=50K  \n",
       "3             0              40   United-States          <=50K  \n",
       "4             0              40            Cuba          <=50K  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Convert the Label column to 0s and 1s instead of strings.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' >50K'], dtype=object)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census['income_bracket'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_fix(label):\n",
    "    if label == ' <=50K':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "census['income_bracket'] = census['income_bracket'].apply(label_fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education  education_num       marital_status  \\\n",
       "0   39          State-gov   Bachelors             13        Never-married   \n",
       "1   50   Self-emp-not-inc   Bachelors             13   Married-civ-spouse   \n",
       "2   38            Private     HS-grad              9             Divorced   \n",
       "3   53            Private        11th              7   Married-civ-spouse   \n",
       "4   28            Private   Bachelors             13   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship    race   gender  capital_gain  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male          2174   \n",
       "1     Exec-managerial         Husband   White     Male             0   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male             0   \n",
       "3   Handlers-cleaners         Husband   Black     Male             0   \n",
       "4      Prof-specialty            Wife   Black   Female             0   \n",
       "\n",
       "   capital_loss  hours_per_week  native_country  income_bracket  \n",
       "0             0              40   United-States               0  \n",
       "1             0              13   United-States               0  \n",
       "2             0              40   United-States               0  \n",
       "3             0              40   United-States               0  \n",
       "4             0              40            Cuba               0  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a Train Test Split on the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = census.drop('income_bracket',axis=1)\n",
    "y_labels = census[\"income_bracket\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_labels, test_size=0.33, random_state=613)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Feature Columns for tf.esitmator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'workclass', 'education', 'education_num', 'marital_status',\n",
       "       'occupation', 'relationship', 'race', 'gender', 'capital_gain',\n",
       "       'capital_loss', 'hours_per_week', 'native_country', 'income_bracket'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Continuous Features\n",
    "age = tf.feature_column.numeric_column('age')\n",
    "capital_gain = tf.feature_column.numeric_column('capital_gain')\n",
    "capital_loss = tf.feature_column.numeric_column('capital_loss')\n",
    "education_num = tf.feature_column.numeric_column('education_num')\n",
    "hours_per_week = tf.feature_column.numeric_column('hours_per_week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_var = ['workclass', 'education', 'marital_status',\n",
    "       'occupation', 'relationship', 'race', 'gender',\n",
    "       'native_country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = []\n",
    "\n",
    "for var in cat_var:\n",
    "    vars = census[var].nunique()\n",
    "    list.append(vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {\n",
    "    cat_var[0]:list[0],\n",
    "    cat_var[1]:list[1],\n",
    "    cat_var[2]:list[2],\n",
    "    cat_var[3]:list[3],\n",
    "    cat_var[4]:list[4],\n",
    "    cat_var[5]:list[5],\n",
    "    cat_var[6]:list[6],\n",
    "    cat_var[7]:list[7],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorical Features\n",
    "gender = tf.feature_column.categorical_column_with_vocabulary_list('gender',['Male','Female'])\n",
    "occupation = tf.feature_column.categorical_column_with_hash_bucket('occupation', hash_bucket_size=15)\n",
    "workclass = tf.feature_column.categorical_column_with_hash_bucket('workclass', hash_bucket_size=9)\n",
    "education = tf.feature_column.categorical_column_with_hash_bucket('education', hash_bucket_size=16)\n",
    "marital_status = tf.feature_column.categorical_column_with_hash_bucket('marital_status', hash_bucket_size=9)\n",
    "native_country = tf.feature_column.categorical_column_with_hash_bucket('native_country', hash_bucket_size=42)\n",
    "race = tf.feature_column.categorical_column_with_hash_bucket('race', hash_bucket_size=5)\n",
    "relationship = tf.feature_column.categorical_column_with_hash_bucket('relationship', hash_bucket_size=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Put all these variables into a single list with the variable name feat_cols **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = ['age', 'workclass', 'education', 'education_num', 'marital_status',\n",
    "       'occupation', 'relationship', 'race', 'gender', 'capital_gain',\n",
    "       'capital_loss', 'hours_per_week', 'native_country']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automated Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the tf.feature_columns for the categorical values. Use vocabulary lists or just use hash buckets. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_feat = ['age', 'capital_gain', 'capital_loss', 'hours_per_week', 'education_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create categorical tensorflow columns:\n",
    "\n",
    "categ_feat = list(X_data.columns)\n",
    " \n",
    "for feat in cont_feat:\n",
    "    categ_feat.remove(feat)\n",
    " \n",
    "categ_feat_cols = [tf.feature_column.categorical_column_with_hash_bucket(feat, hash_bucket_size= 1000) for feat in categ_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_HashedCategoricalColumn(key='workclass', hash_bucket_size=1000, dtype=tf.string),\n",
       " _HashedCategoricalColumn(key='education', hash_bucket_size=1000, dtype=tf.string),\n",
       " _HashedCategoricalColumn(key='marital_status', hash_bucket_size=1000, dtype=tf.string),\n",
       " _HashedCategoricalColumn(key='occupation', hash_bucket_size=1000, dtype=tf.string),\n",
       " _HashedCategoricalColumn(key='relationship', hash_bucket_size=1000, dtype=tf.string),\n",
       " _HashedCategoricalColumn(key='race', hash_bucket_size=1000, dtype=tf.string),\n",
       " _HashedCategoricalColumn(key='gender', hash_bucket_size=1000, dtype=tf.string),\n",
       " _HashedCategoricalColumn(key='native_country', hash_bucket_size=1000, dtype=tf.string)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categ_feat_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the continuous feature_columns for the continuous values using numeric_column **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create continuous tensorflow columns:\n",
    "\n",
    "cont_feat_cols = [tf.feature_column.numeric_column(feat) for feat in cont_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = cont_feat_cols + categ_feat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='capital_gain', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='capital_loss', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='hours_per_week', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='education_num', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _HashedCategoricalColumn(key='workclass', hash_bucket_size=1000, dtype=tf.string),\n",
       " _HashedCategoricalColumn(key='education', hash_bucket_size=1000, dtype=tf.string),\n",
       " _HashedCategoricalColumn(key='marital_status', hash_bucket_size=1000, dtype=tf.string),\n",
       " _HashedCategoricalColumn(key='occupation', hash_bucket_size=1000, dtype=tf.string),\n",
       " _HashedCategoricalColumn(key='relationship', hash_bucket_size=1000, dtype=tf.string),\n",
       " _HashedCategoricalColumn(key='race', hash_bucket_size=1000, dtype=tf.string),\n",
       " _HashedCategoricalColumn(key='gender', hash_bucket_size=1000, dtype=tf.string),\n",
       " _HashedCategoricalColumn(key='native_country', hash_bucket_size=1000, dtype=tf.string)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Input Function\n",
    "\n",
    "** Batch_size is up to you. But do make sure to shuffle!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_func = tf.estimator.inputs.pandas_input_fn(x=X_train, y=y_train, batch_size=100, num_epochs=None, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create your model with tf.estimator\n",
    "\n",
    "**Create a LinearClassifier.(If you want to use a DNNClassifier, keep in mind you'll need to create embedded columns out of the cateogrical feature that use strings, check out the previous lecture on this for more info.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Y\\AppData\\Local\\Temp\\tmpycuhekr7\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Y\\\\AppData\\\\Local\\\\Temp\\\\tmpycuhekr7', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001FAEEC8DCC0>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.LinearClassifier(feature_columns=feat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Train your model on the data, for at least 5000 steps. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\Y\\AppData\\Local\\Temp\\tmpycuhekr7\\model.ckpt.\n",
      "INFO:tensorflow:loss = 69.3147, step = 1\n",
      "INFO:tensorflow:global_step/sec: 187.003\n",
      "INFO:tensorflow:loss = 328.974, step = 101 (0.535 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.484\n",
      "INFO:tensorflow:loss = 234.177, step = 201 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.488\n",
      "INFO:tensorflow:loss = 243.074, step = 301 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.753\n",
      "INFO:tensorflow:loss = 178.434, step = 401 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.815\n",
      "INFO:tensorflow:loss = 363.91, step = 501 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.288\n",
      "INFO:tensorflow:loss = 130.949, step = 601 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.763\n",
      "INFO:tensorflow:loss = 250.76, step = 701 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.025\n",
      "INFO:tensorflow:loss = 355.177, step = 801 (0.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.713\n",
      "INFO:tensorflow:loss = 69.8768, step = 901 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.453\n",
      "INFO:tensorflow:loss = 87.2335, step = 1001 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.79\n",
      "INFO:tensorflow:loss = 102.526, step = 1101 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.24\n",
      "INFO:tensorflow:loss = 91.1289, step = 1201 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.367\n",
      "INFO:tensorflow:loss = 46.0441, step = 1301 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.339\n",
      "INFO:tensorflow:loss = 45.204, step = 1401 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.543\n",
      "INFO:tensorflow:loss = 44.5302, step = 1501 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 372.736\n",
      "INFO:tensorflow:loss = 241.038, step = 1601 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.495\n",
      "INFO:tensorflow:loss = 73.3581, step = 1701 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.453\n",
      "INFO:tensorflow:loss = 76.9274, step = 1801 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.703\n",
      "INFO:tensorflow:loss = 23.0794, step = 1901 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.58\n",
      "INFO:tensorflow:loss = 44.4263, step = 2001 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.612\n",
      "INFO:tensorflow:loss = 75.6648, step = 2101 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.073\n",
      "INFO:tensorflow:loss = 33.7988, step = 2201 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.508\n",
      "INFO:tensorflow:loss = 50.9256, step = 2301 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.97\n",
      "INFO:tensorflow:loss = 38.0984, step = 2401 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.456\n",
      "INFO:tensorflow:loss = 37.5625, step = 2501 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 404.87\n",
      "INFO:tensorflow:loss = 66.1018, step = 2601 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.084\n",
      "INFO:tensorflow:loss = 45.9254, step = 2701 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.718\n",
      "INFO:tensorflow:loss = 50.9252, step = 2801 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.751\n",
      "INFO:tensorflow:loss = 33.1947, step = 2901 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.084\n",
      "INFO:tensorflow:loss = 46.5949, step = 3001 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.484\n",
      "INFO:tensorflow:loss = 80.405, step = 3101 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.475\n",
      "INFO:tensorflow:loss = 46.2968, step = 3201 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.349\n",
      "INFO:tensorflow:loss = 111.82, step = 3301 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 366.952\n",
      "INFO:tensorflow:loss = 33.2775, step = 3401 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.944\n",
      "INFO:tensorflow:loss = 32.9778, step = 3501 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.01\n",
      "INFO:tensorflow:loss = 56.3662, step = 3601 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.677\n",
      "INFO:tensorflow:loss = 68.91, step = 3701 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.058\n",
      "INFO:tensorflow:loss = 36.8077, step = 3801 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.701\n",
      "INFO:tensorflow:loss = 37.9091, step = 3901 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.304\n",
      "INFO:tensorflow:loss = 182.747, step = 4001 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.82\n",
      "INFO:tensorflow:loss = 64.519, step = 4101 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.842\n",
      "INFO:tensorflow:loss = 41.4576, step = 4201 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.977\n",
      "INFO:tensorflow:loss = 275.715, step = 4301 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.177\n",
      "INFO:tensorflow:loss = 44.4159, step = 4401 (0.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.365\n",
      "INFO:tensorflow:loss = 36.1514, step = 4501 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.164\n",
      "INFO:tensorflow:loss = 37.8508, step = 4601 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.778\n",
      "INFO:tensorflow:loss = 29.7143, step = 4701 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.824\n",
      "INFO:tensorflow:loss = 241.861, step = 4801 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.488\n",
      "INFO:tensorflow:loss = 34.9378, step = 4901 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.905\n",
      "INFO:tensorflow:loss = 31.7718, step = 5001 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.67\n",
      "INFO:tensorflow:loss = 47.892, step = 5101 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.101\n",
      "INFO:tensorflow:loss = 33.6388, step = 5201 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.654\n",
      "INFO:tensorflow:loss = 50.7488, step = 5301 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.161\n",
      "INFO:tensorflow:loss = 28.9695, step = 5401 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.398\n",
      "INFO:tensorflow:loss = 178.79, step = 5501 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.41\n",
      "INFO:tensorflow:loss = 38.5369, step = 5601 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.911\n",
      "INFO:tensorflow:loss = 28.438, step = 5701 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.072\n",
      "INFO:tensorflow:loss = 25.3886, step = 5801 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.289\n",
      "INFO:tensorflow:loss = 166.35, step = 5901 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.543\n",
      "INFO:tensorflow:loss = 70.5773, step = 6001 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.361\n",
      "INFO:tensorflow:loss = 28.2111, step = 6101 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.402\n",
      "INFO:tensorflow:loss = 67.4731, step = 6201 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.769\n",
      "INFO:tensorflow:loss = 37.1088, step = 6301 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.285\n",
      "INFO:tensorflow:loss = 18.5227, step = 6401 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.572\n",
      "INFO:tensorflow:loss = 60.8185, step = 6501 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 383.416\n",
      "INFO:tensorflow:loss = 24.8726, step = 6601 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.187\n",
      "INFO:tensorflow:loss = 27.7448, step = 6701 (0.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.749\n",
      "INFO:tensorflow:loss = 20.5139, step = 6801 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.896\n",
      "INFO:tensorflow:loss = 29.8355, step = 6901 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.665\n",
      "INFO:tensorflow:loss = 125.791, step = 7001 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.884\n",
      "INFO:tensorflow:loss = 88.4487, step = 7101 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.435\n",
      "INFO:tensorflow:loss = 30.6504, step = 7201 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 389.625\n",
      "INFO:tensorflow:loss = 165.254, step = 7301 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.88\n",
      "INFO:tensorflow:loss = 51.635, step = 7401 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.853\n",
      "INFO:tensorflow:loss = 91.4433, step = 7501 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 366.175\n",
      "INFO:tensorflow:loss = 45.8558, step = 7601 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.957\n",
      "INFO:tensorflow:loss = 28.5262, step = 7701 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.931\n",
      "INFO:tensorflow:loss = 95.1154, step = 7801 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.698\n",
      "INFO:tensorflow:loss = 111.888, step = 7901 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.802\n",
      "INFO:tensorflow:loss = 75.1562, step = 8001 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.783\n",
      "INFO:tensorflow:loss = 54.2454, step = 8101 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.918\n",
      "INFO:tensorflow:loss = 45.4236, step = 8201 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 369.584\n",
      "INFO:tensorflow:loss = 23.146, step = 8301 (0.271 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 362.332\n",
      "INFO:tensorflow:loss = 25.5498, step = 8401 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 388.582\n",
      "INFO:tensorflow:loss = 50.323, step = 8501 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 387.809\n",
      "INFO:tensorflow:loss = 43.6843, step = 8601 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.339\n",
      "INFO:tensorflow:loss = 46.8222, step = 8701 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.422\n",
      "INFO:tensorflow:loss = 80.3725, step = 8801 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.198\n",
      "INFO:tensorflow:loss = 30.9092, step = 8901 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.147\n",
      "INFO:tensorflow:loss = 26.7919, step = 9001 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.255\n",
      "INFO:tensorflow:loss = 45.6863, step = 9101 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.637\n",
      "INFO:tensorflow:loss = 31.1244, step = 9201 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.598\n",
      "INFO:tensorflow:loss = 50.1205, step = 9301 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.222\n",
      "INFO:tensorflow:loss = 52.5821, step = 9401 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.808\n",
      "INFO:tensorflow:loss = 88.4607, step = 9501 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.067\n",
      "INFO:tensorflow:loss = 88.5572, step = 9601 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.758\n",
      "INFO:tensorflow:loss = 30.1751, step = 9701 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.842\n",
      "INFO:tensorflow:loss = 40.7332, step = 9801 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.247\n",
      "INFO:tensorflow:loss = 36.3994, step = 9901 (0.334 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into C:\\Users\\Y\\AppData\\Local\\Temp\\tmpycuhekr7\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 321.953.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearClassifier at 0x1faeec8d550>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=input_func,steps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "** Create a prediction input function. Remember to only supprt X_test data and keep shuffle=False. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_input_func = tf.estimator.inputs.pandas_input_fn(\n",
    "      x=X_test,\n",
    "      y=y_test,\n",
    "      batch_size=len(X_test),\n",
    "      num_epochs=1,\n",
    "      shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-08-21:05:35\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Y\\AppData\\Local\\Temp\\tmpycuhekr7\\model.ckpt-10000\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-08-21:05:37\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.828401, accuracy_baseline = 0.759538, auc = 0.874883, auc_precision_recall = 0.648423, average_loss = 2.00321, global_step = 10000, label/mean = 0.240462, loss = 21526.5, prediction/mean = 0.268233\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(eval_input_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.82840127,\n",
       " 'accuracy_baseline': 0.75953841,\n",
       " 'auc': 0.87488323,\n",
       " 'auc_precision_recall': 0.64842331,\n",
       " 'average_loss': 2.0032141,\n",
       " 'global_step': 10000,\n",
       " 'label/mean': 0.24046157,\n",
       " 'loss': 21526.539,\n",
       " 'prediction/mean': 0.26823294}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Use model.predict() and pass in your input function. This will produce a generator of predictions, which you can then transform into a list, with list() **\n",
    "\n",
    "** Create a prediction input function. Remember to only supprt X_test data and keep shuffle=False. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_fn = tf.estimator.inputs.pandas_input_fn(x=X_test,batch_size=len(X_test),shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Use model.predict() and pass in your input function. This will produce a generator of predictions, which you can then transform into a list, with list() **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Y\\AppData\\Local\\Temp\\tmpycuhekr7\\model.ckpt-10000\n"
     ]
    }
   ],
   "source": [
    "predictions = list(model.predict(input_fn=pred_fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Each item in your list will look like this: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_ids': array([1], dtype=int64),\n",
       " 'classes': array([b'1'], dtype=object),\n",
       " 'logistic': array([ 0.88647002], dtype=float32),\n",
       " 'logits': array([ 2.05518055], dtype=float32),\n",
       " 'probabilities': array([ 0.11352997,  0.88647002], dtype=float32)}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a list of only the class_ids key values from the prediction list of dictionaries, these are the predictions you will use to compare against the real y_test values. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = []\n",
    "for pred in predictions:\n",
    "    final_preds.append(pred['class_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 0, 0, 0, 0, 1, 0, 0]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_preds[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import classification_report from sklearn.metrics and then see if you can figure out how to use it to easily get a full report of your model's performance on the test data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.89      0.89      8162\n",
      "          1       0.64      0.64      0.64      2584\n",
      "\n",
      "avg / total       0.83      0.83      0.83     10746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,final_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNNClassifier\n",
    "\n",
    "Create a LinearClassifier.(If you want to use a DNNClassifier, keep in mind you'll need to create embedded columns out of the cateogrical feature that use strings, check out the previous lecture on this for more info.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorical Features\n",
    "gender = tf.feature_column.categorical_column_with_vocabulary_list('gender',['Male','Female'])\n",
    "occupation = tf.feature_column.categorical_column_with_hash_bucket('occupation', hash_bucket_size=15)\n",
    "workclass = tf.feature_column.categorical_column_with_hash_bucket('workclass', hash_bucket_size=9)\n",
    "education = tf.feature_column.categorical_column_with_hash_bucket('education', hash_bucket_size=16)\n",
    "marital_status = tf.feature_column.categorical_column_with_hash_bucket('marital_status', hash_bucket_size=9)\n",
    "native_country = tf.feature_column.categorical_column_with_hash_bucket('native_country', hash_bucket_size=42)\n",
    "race = tf.feature_column.categorical_column_with_hash_bucket('race', hash_bucket_size=5)\n",
    "relationship = tf.feature_column.categorical_column_with_hash_bucket('relationship', hash_bucket_size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorical Features\n",
    "embedded_group_column_g = tf.feature_column.embedding_column(gender, dimension=2)\n",
    "embedded_group_column_o = tf.feature_column.embedding_column(occupation, dimension=15)\n",
    "embedded_group_column_wc = tf.feature_column.embedding_column(workclass, dimension=9)\n",
    "embedded_group_column_e = tf.feature_column.embedding_column(education, dimension=16)\n",
    "embedded_group_column_ms = tf.feature_column.embedding_column(marital_status, dimension=9)\n",
    "embedded_group_column_nc = tf.feature_column.embedding_column(native_country, dimension=42)\n",
    "embedded_group_column_ra = tf.feature_column.embedding_column(race, dimension=5)\n",
    "embedded_group_column_re = tf.feature_column.embedding_column(relationship, dimension=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Continuous Features\n",
    "age = tf.feature_column.numeric_column('age')\n",
    "capital_gain = tf.feature_column.numeric_column('capital_gain')\n",
    "capital_loss = tf.feature_column.numeric_column('capital_loss')\n",
    "education_num = tf.feature_column.numeric_column('education_num')\n",
    "hours_per_week = tf.feature_column.numeric_column('hours_per_week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [embedded_group_column_g, embedded_group_column_o, embedded_group_column_wc, embedded_group_column_e,\n",
    "            embedded_group_column_ms, embedded_group_column_nc, embedded_group_column_ra, embedded_group_column_re, \n",
    "             age, capital_gain, capital_loss, hours_per_week, education_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_func = tf.estimator.inputs.pandas_input_fn(x=X_train,y=y_train,batch_size=10,num_epochs=1000,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Y\\AppData\\Local\\Temp\\tmpfmwur7k_\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Y\\\\AppData\\\\Local\\\\Temp\\\\tmpfmwur7k_', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001FAF0BC4080>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "dnn_model = tf.estimator.DNNClassifier(hidden_units=[10, 20, 20, 20, 10],feature_columns=feat_cols,n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\Y\\AppData\\Local\\Temp\\tmpfmwur7k_\\model.ckpt.\n",
      "INFO:tensorflow:loss = 104.485, step = 1\n",
      "INFO:tensorflow:global_step/sec: 206.699\n",
      "INFO:tensorflow:loss = 3.11951, step = 101 (0.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.403\n",
      "INFO:tensorflow:loss = 4.29162, step = 201 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.469\n",
      "INFO:tensorflow:loss = 4.30677, step = 301 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.212\n",
      "INFO:tensorflow:loss = 3.46948, step = 401 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.372\n",
      "INFO:tensorflow:loss = 5.30336, step = 501 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.194\n",
      "INFO:tensorflow:loss = 3.8669, step = 601 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.396\n",
      "INFO:tensorflow:loss = 1.17031, step = 701 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.915\n",
      "INFO:tensorflow:loss = 5.50618, step = 801 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.234\n",
      "INFO:tensorflow:loss = 1.60339, step = 901 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 408.747\n",
      "INFO:tensorflow:loss = 5.2762, step = 1001 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.358\n",
      "INFO:tensorflow:loss = 3.13189, step = 1101 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 540.668\n",
      "INFO:tensorflow:loss = 2.66156, step = 1201 (0.180 sec)\n",
      "INFO:tensorflow:global_step/sec: 524.278\n",
      "INFO:tensorflow:loss = 2.31589, step = 1301 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.534\n",
      "INFO:tensorflow:loss = 2.59488, step = 1401 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.198\n",
      "INFO:tensorflow:loss = 6.82225, step = 1501 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.497\n",
      "INFO:tensorflow:loss = 2.13918, step = 1601 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.073\n",
      "INFO:tensorflow:loss = 7.05753, step = 1701 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.314\n",
      "INFO:tensorflow:loss = 6.6224, step = 1801 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 404.448\n",
      "INFO:tensorflow:loss = 3.35548, step = 1901 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.581\n",
      "INFO:tensorflow:loss = 2.84783, step = 2001 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.102\n",
      "INFO:tensorflow:loss = 3.20211, step = 2101 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.389\n",
      "INFO:tensorflow:loss = 3.45526, step = 2201 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.063\n",
      "INFO:tensorflow:loss = 2.26127, step = 2301 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 369.386\n",
      "INFO:tensorflow:loss = 3.64954, step = 2401 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.037\n",
      "INFO:tensorflow:loss = 2.90102, step = 2501 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.393\n",
      "INFO:tensorflow:loss = 2.58702, step = 2601 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 493.532\n",
      "INFO:tensorflow:loss = 2.46149, step = 2701 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.431\n",
      "INFO:tensorflow:loss = 1.81266, step = 2801 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 402.547\n",
      "INFO:tensorflow:loss = 2.49759, step = 2901 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 489.088\n",
      "INFO:tensorflow:loss = 1.59599, step = 3001 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 503.126\n",
      "INFO:tensorflow:loss = 2.57104, step = 3101 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.843\n",
      "INFO:tensorflow:loss = 2.42311, step = 3201 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.429\n",
      "INFO:tensorflow:loss = 1.43217, step = 3301 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.604\n",
      "INFO:tensorflow:loss = 1.80129, step = 3401 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.921\n",
      "INFO:tensorflow:loss = 6.89335, step = 3501 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 502.653\n",
      "INFO:tensorflow:loss = 5.26593, step = 3601 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 506.57\n",
      "INFO:tensorflow:loss = 3.08745, step = 3701 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.784\n",
      "INFO:tensorflow:loss = 2.9455, step = 3801 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.51\n",
      "INFO:tensorflow:loss = 2.24431, step = 3901 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.218\n",
      "INFO:tensorflow:loss = 2.40505, step = 4001 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.538\n",
      "INFO:tensorflow:loss = 3.45252, step = 4101 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 383.592\n",
      "INFO:tensorflow:loss = 2.34049, step = 4201 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 402.275\n",
      "INFO:tensorflow:loss = 4.86995, step = 4301 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.253\n",
      "INFO:tensorflow:loss = 3.44747, step = 4401 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 502.923\n",
      "INFO:tensorflow:loss = 2.09723, step = 4501 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.907\n",
      "INFO:tensorflow:loss = 1.49312, step = 4601 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 396.158\n",
      "INFO:tensorflow:loss = 4.54554, step = 4701 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 538.209\n",
      "INFO:tensorflow:loss = 4.22563, step = 4801 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 495.727\n",
      "INFO:tensorflow:loss = 2.89577, step = 4901 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 483.874\n",
      "INFO:tensorflow:loss = 3.36516, step = 5001 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 514.253\n",
      "INFO:tensorflow:loss = 0.845764, step = 5101 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.095\n",
      "INFO:tensorflow:loss = 4.81896, step = 5201 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 503.711\n",
      "INFO:tensorflow:loss = 2.37685, step = 5301 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.255\n",
      "INFO:tensorflow:loss = 5.16943, step = 5401 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 533.278\n",
      "INFO:tensorflow:loss = 3.24059, step = 5501 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.925\n",
      "INFO:tensorflow:loss = 3.02911, step = 5601 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.621\n",
      "INFO:tensorflow:loss = 3.89783, step = 5701 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.034\n",
      "INFO:tensorflow:loss = 2.91213, step = 5801 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 404.378\n",
      "INFO:tensorflow:loss = 3.22489, step = 5901 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.474\n",
      "INFO:tensorflow:loss = 1.67603, step = 6001 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.368\n",
      "INFO:tensorflow:loss = 3.69785, step = 6101 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.16\n",
      "INFO:tensorflow:loss = 2.65484, step = 6201 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.982\n",
      "INFO:tensorflow:loss = 2.80074, step = 6301 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 393.506\n",
      "INFO:tensorflow:loss = 5.03167, step = 6401 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.067\n",
      "INFO:tensorflow:loss = 4.87557, step = 6501 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.093\n",
      "INFO:tensorflow:loss = 3.29363, step = 6601 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.66\n",
      "INFO:tensorflow:loss = 1.96826, step = 6701 (0.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.583\n",
      "INFO:tensorflow:loss = 3.27748, step = 6801 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.073\n",
      "INFO:tensorflow:loss = 2.50316, step = 6901 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 392.701\n",
      "INFO:tensorflow:loss = 3.04401, step = 7001 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.248\n",
      "INFO:tensorflow:loss = 6.03329, step = 7101 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.931\n",
      "INFO:tensorflow:loss = 3.12461, step = 7201 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 394.728\n",
      "INFO:tensorflow:loss = 3.23943, step = 7301 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.421\n",
      "INFO:tensorflow:loss = 0.840313, step = 7401 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.49\n",
      "INFO:tensorflow:loss = 2.59041, step = 7501 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.335\n",
      "INFO:tensorflow:loss = 2.8808, step = 7601 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 478.355\n",
      "INFO:tensorflow:loss = 5.5374, step = 7701 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.729\n",
      "INFO:tensorflow:loss = 2.32835, step = 7801 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 489.544\n",
      "INFO:tensorflow:loss = 2.83022, step = 7901 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.374\n",
      "INFO:tensorflow:loss = 0.925573, step = 8001 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 494.619\n",
      "INFO:tensorflow:loss = 2.91553, step = 8101 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.842\n",
      "INFO:tensorflow:loss = 2.71951, step = 8201 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.898\n",
      "INFO:tensorflow:loss = 2.5051, step = 8301 (0.228 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 426.796\n",
      "INFO:tensorflow:loss = 4.98465, step = 8401 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 507.443\n",
      "INFO:tensorflow:loss = 3.14388, step = 8501 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.323\n",
      "INFO:tensorflow:loss = 4.14006, step = 8601 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.432\n",
      "INFO:tensorflow:loss = 2.89427, step = 8701 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.154\n",
      "INFO:tensorflow:loss = 1.04102, step = 8801 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.646\n",
      "INFO:tensorflow:loss = 1.42547, step = 8901 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.002\n",
      "INFO:tensorflow:loss = 3.87958, step = 9001 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.438\n",
      "INFO:tensorflow:loss = 2.24313, step = 9101 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 409.108\n",
      "INFO:tensorflow:loss = 0.887338, step = 9201 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 467.309\n",
      "INFO:tensorflow:loss = 1.99763, step = 9301 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.465\n",
      "INFO:tensorflow:loss = 7.8857, step = 9401 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.826\n",
      "INFO:tensorflow:loss = 1.69347, step = 9501 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.647\n",
      "INFO:tensorflow:loss = 2.50361, step = 9601 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.347\n",
      "INFO:tensorflow:loss = 5.71759, step = 9701 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.169\n",
      "INFO:tensorflow:loss = 3.59362, step = 9801 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.92\n",
      "INFO:tensorflow:loss = 3.92006, step = 9901 (0.216 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into C:\\Users\\Y\\AppData\\Local\\Temp\\tmpfmwur7k_\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.27863.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x1faf0bc4908>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_model.train(input_fn=input_func,steps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_input_func = tf.estimator.inputs.pandas_input_fn(\n",
    "      x=X_test,\n",
    "      y=y_test,\n",
    "      batch_size=10,\n",
    "      num_epochs=1,\n",
    "      shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-08-21:44:55\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Y\\AppData\\Local\\Temp\\tmpfmwur7k_\\model.ckpt-10000\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-08-21:44:58\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.838079, accuracy_baseline = 0.759538, auc = 0.890019, auc_precision_recall = 0.734187, average_loss = 0.341987, global_step = 10000, label/mean = 0.240462, loss = 3.4186, prediction/mean = 0.235807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.83807927,\n",
       " 'accuracy_baseline': 0.75953841,\n",
       " 'auc': 0.89001858,\n",
       " 'auc_precision_recall': 0.73418653,\n",
       " 'average_loss': 0.34198725,\n",
       " 'global_step': 10000,\n",
       " 'label/mean': 0.24046157,\n",
       " 'loss': 3.4186001,\n",
       " 'prediction/mean': 0.23580664}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_model.evaluate(eval_input_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
